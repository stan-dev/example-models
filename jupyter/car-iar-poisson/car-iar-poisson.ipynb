{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting the Model to the Scotland Lip Cancer Dataset\n",
    "\n",
    "In this section, we'll implement the Besag-York-Mollié (BYM) model for the Scotland dataset using [CmdStanPy](https://mc-stan.org/cmdstanpy/), a lightweight interface to Stan for Python. We'll use the Python standard library's [json](https://docs.python.org/3/library/json.html) module to load and parse our data, and [numpy](https://numpy.org/) for numerical operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cmdstanpy\n",
    "from cmdstanpy import CmdStanModel\n",
    "import numpy as np\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not cmdstanpy.cmdstan_path():\n",
    "    cmdstanpy.install_cmdstan()\n",
    "\n",
    "with open(\"data/scotland_data.json\") as file:\n",
    "    scotland_data = json.load(file)\n",
    "\n",
    "def munge_car_data_for_stan(adjBUGS, numBUGS):\n",
    "    N = len(numBUGS)\n",
    "    nn = numBUGS\n",
    "    N_edges = len(adjBUGS) // 2\n",
    "    node1 = np.zeros(N_edges, dtype=int)\n",
    "    node2 = np.zeros(N_edges, dtype=int)\n",
    "    iAdj = 0\n",
    "    iEdge = 0\n",
    "    \n",
    "    for i in range(N):\n",
    "        for j in range(nn[i]):\n",
    "            iAdj += 1\n",
    "            if i + 1 < adjBUGS[iAdj - 1]:\n",
    "                iEdge += 1\n",
    "                node1[iEdge - 1] = i + 1\n",
    "                node2[iEdge - 1] = adjBUGS[iAdj - 1]\n",
    "    \n",
    "    return {\n",
    "        \"N\": N,\n",
    "        \"N_edges\": N_edges,\n",
    "        \"node1\": node1,\n",
    "        \"node2\": node2\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nbs = munge_car_data_for_stan(\n",
    "    scotland_data[\"adj\"], scotland_data[\"num\"]\n",
    ")\n",
    "\n",
    "scotland_data_subset = {\n",
    "    \"y\": np.array(scotland_data[\"y\"]),\n",
    "    \"x\": np.array(scotland_data[\"x\"]) * 0.1,\n",
    "    \"E\": np.array(scotland_data[\"E\"])\n",
    "}\n",
    "\n",
    "data = {**nbs, **scotland_data_subset}\n",
    "bym_model = CmdStanModel(stan_file=\"stan/bym_predictor_plus_offset.stan\")\n",
    "bym_scot_stanfit = bym_model.sample(data=data, show_progress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vars = [\n",
    "    \"lp__\",\n",
    "    \"beta0\",\n",
    "    \"beta1\",\n",
    "    \"sigma_phi\",\n",
    "    \"tau_phi\",\n",
    "    \"sigma_theta\",\n",
    "    \"tau_theta\",\n",
    "    \"mu[5]\",\n",
    "    \"phi[5]\",\n",
    "    \"theta[5]\",\n",
    "]\n",
    "bym_scot_stanfit.summary().loc[vars]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BYM2: improving the parameterization of the Besag, York, and Mollié model\n",
    "\n",
    "In the following section, we implement the BYM2 model, which improves upon the parameterization of the original BYM model. As there is no native implementation of INLA in Python, we calculate the scaling factor from scratch using the [SciPy](https://scipy.org/) library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.sparse as sp\n",
    "\n",
    "def get_scaling_factor(node1, node2, N):\n",
    "     # Convert to 0-indexing\n",
    "    node1 = node1 - 1\n",
    "    node2 = node2 - 1\n",
    "\n",
    "    # Create adjacency matrix based on node1 and node2\n",
    "    A = sp.coo_matrix((np.ones(len(node1)), (node1, node2)), shape=(N, N))\n",
    "\n",
    "    # Create the ICAR precision matrix\n",
    "    A = A + A.T\n",
    "    Q = sp.diags(A.sum(axis=1).A1) - A\n",
    "\n",
    "    # Compute the pseudo-inverse of the precision matrix\n",
    "    Q_pinv = np.linalg.pinv(Q.todense())\n",
    "        \n",
    "    # Extract the diagonal elements\n",
    "    cov_diag = np.diag(Q_pinv)\n",
    "\n",
    "    # Compute the geometric mean of the variances\n",
    "    scaling_factor = np.exp(np.mean(np.log(cov_diag)))\n",
    "    \n",
    "    return scaling_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nbs = munge_car_data_for_stan(\n",
    "    scotland_data[\"adj\"], scotland_data[\"num\"]\n",
    ")\n",
    "\n",
    "scotland_data_subset = {\n",
    "    \"y\": np.array(scotland_data[\"y\"]),\n",
    "    \"x\": np.array(scotland_data[\"x\"]) * 0.1,\n",
    "    \"E\": np.array(scotland_data[\"E\"])\n",
    "}\n",
    "\n",
    "scaling_factor = get_scaling_factor(nbs[\"node1\"], nbs[\"node2\"], nbs[\"N\"])\n",
    "\n",
    "data = {**nbs, **scotland_data_subset, **{\"scaling_factor\": scaling_factor}}\n",
    "bym2_model = CmdStanModel(stan_file=\"stan/bym2_predictor_plus_offset.stan\")\n",
    "bym2_scot_stanfit = bym2_model.sample(data=data, show_progress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vars = [\n",
    "    \"lp__\",\n",
    "    \"beta0\",\n",
    "    \"beta1\",\n",
    "    \"sigma\",  \"rho\", \"mu[5]\",\n",
    "    \"phi[5]\", \"theta[5]\"\n",
    "]\n",
    "bym2_scot_stanfit.summary().loc[vars]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bigger data: from 56 counties in Scotland to 1921 census tracts in New York City\n",
    "\n",
    "In this example, we'll apply the BYM2 model to a dataset of reported traffic accidents in New York City involving cars and either pedestrians or bicyclists. The data, collected between 2001 and 2009, is aggregated at the census tract level. For this analysis, we'll focus on the 2001 data, which covers 1,921 census tracts.\n",
    "We begin by loading the dataset, `nyc_subset.json`, using [Pandas](https://pandas.pydata.org/). This file contains a list of the 1,921 census tract IDs (`nyc_tractIDs`), the count of injuries per tract in 2001 (`events_2001`), and the 2001 population per census tract (`pop_2001`). To visualize the relationship between injury counts and population across census tracts, we'll create a scatterplot using [plotnine](https://plotnine.org/), a Python implementation of the grammar of graphics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotnine as p9\n",
    "\n",
    "p9.theme_set(\n",
    "    p9.theme_grey()\n",
    "    + p9.theme(\n",
    "        text=p9.element_text(size=10),\n",
    "        plot_title=p9.element_text(size=14),\n",
    "        axis_title_x=p9.element_text(size=12),\n",
    "        axis_title_y=p9.element_text(size=12),\n",
    "        axis_text_x=p9.element_text(size=8),\n",
    "        axis_text_y=p9.element_text(size=8),\n",
    "    )\n",
    ")\n",
    "\n",
    "nyc_subset = pd.read_json(\"data/nyc_subset.json\", dtype={\"nyc_tractIDs\": str})\n",
    "\n",
    "(\n",
    "    p9.ggplot(data=nyc_subset, mapping=p9.aes(x=\"pop_2001\", y=\"events_2001\")) + \n",
    "    p9.geom_point() + \n",
    "    p9.scale_x_continuous(trans=\"log\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To incorporate spatial information for New York City, we'll use data stored in the `nycTracts10` directory. We'll load this spatial data using [GeoPandas](https://geopandas.org/en/stable/), a powerful library for handling geospatial data in Python. In addition to GeoPandas, we'll utilize [libpysal](https://pysal.org/libpysal/), a Python spatial analysis library to generate a list of neighboring census tracts for each tract."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "\n",
    "nyc_shp = gpd.read_file(\"data/nycTracts10/nycTracts10.shp\")\n",
    "nyc_tractIDs = nyc_subset[\"nyc_tractIDs\"]\n",
    "nyc_shp_subset = nyc_shp.merge(\n",
    "    nyc_subset, how=\"inner\", left_on=\"GEOID10\", right_on=\"nyc_tractIDs\"\n",
    ").assign(log_pop_2001=lambda df: np.log(df[\"pop_2001\"] + 0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import libpysal as sa\n",
    "\n",
    "# Create a spatial weights object\n",
    "nyc_nbs = sa.weights.Queen(nyc_shp_subset['geometry'])\n",
    "\n",
    "# List of nodes\n",
    "nodes = nyc_nbs.neighbors.keys()\n",
    "\n",
    "# List of edges\n",
    "edges = [(node+1, neighbor+1) for node in nodes for neighbor in nyc_nbs.neighbors[node]]\n",
    "\n",
    "# Unzip edges to get node1 and node2 and convert to numpy arrays\n",
    "node1, node2 = zip(*edges)\n",
    "node1 = np.array(node1)\n",
    "node2 = np.array(node2)\n",
    "\n",
    "# Compute the scaling factor\n",
    "scaling_factor = get_scaling_factor(node1, node2, len(nyc_shp_subset))\n",
    "\n",
    "N = len(nyc_shp_subset)\n",
    "y = nyc_shp_subset[\"events_2001\"].values\n",
    "E = nyc_shp_subset[\"pop_2001\"].values\n",
    "\n",
    "# Set population > 0\n",
    "E[E < 10] = 10\n",
    "\n",
    "data = {\n",
    "    \"N\": N,\n",
    "    \"N_edges\": len(edges),\n",
    "    \"node1\": node1,\n",
    "    \"node2\": node2,\n",
    "    \"y\": y,\n",
    "    \"E\": E,\n",
    "    \"scaling_factor\": scaling_factor\n",
    "}\n",
    "\n",
    "bym2_model = CmdStanModel(stan_file=\"stan/bym2_offset_only.stan\")\n",
    "bym2_nyc_stanfit = bym2_model.sample(data=data, show_progress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vars = [\n",
    "    \"beta0\", \"rho\", \"sigma\",\"mu[1]\", \"mu[2]\", \"mu[3]\", \"mu[500]\", \n",
    "    \"mu[1000]\", \"mu[1500]\", \"mu[1900]\", \"phi[1]\", \"phi[2]\", \"phi[3]\", \n",
    "    \"phi[500]\", \"phi[1000]\", \"phi[1500]\", \"phi[1900]\", \"theta[1]\", \n",
    "    \"theta[2]\", \"theta[3]\", \"theta[500]\", \"theta[1000]\", \"theta[1500]\", \n",
    "    \"theta[1900]\"\n",
    "]\n",
    "\n",
    "bym2_nyc_model_summary = bym2_nyc_stanfit.summary()\n",
    "bym2_nyc_model_summary.loc[vars]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To visualize the spatial data, model fits, and neighborhood graph on an interactive map, we utilize [Folium](https://python-visualization.github.io/folium/latest/). This Python library is particularly useful for creating leaflet.js maps, allowing us to display the geographical boundaries of the census tracts and create a choropleth map based on injury counts and population."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import folium\n",
    "\n",
    "centroids = nyc_shp_subset['geometry'].centroid\n",
    "m = folium.Map(location=[centroids.y.mean(), centroids.x.mean()], zoom_start=12)\n",
    "\n",
    "# Add the geometries to the folium map\n",
    "for geom in nyc_shp_subset.geometry:\n",
    "    geo_json = folium.GeoJson(data=geom.__geo_interface__)\n",
    "    geo_json.add_to(m)\n",
    "\n",
    "for i, neighbors in nyc_nbs.neighbors.items():\n",
    "    for neighbor in neighbors:\n",
    "        # Get the coordinates of the centroids of neighboring polygons\n",
    "        p1 = [centroids.iloc[i].y, centroids.iloc[i].x]\n",
    "        p2 = [centroids.iloc[neighbor].y, centroids.iloc[neighbor].x]\n",
    "\n",
    "        # Add a line between the centroids of neighboring polygons\n",
    "        folium.PolyLine([p1, p2], color=\"blue\", weight=2).add_to(m)\n",
    "\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following plot, the first panel shows the 2001 log population per census tract and the second panel shows the raw number of 2001 events."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the map centered on the centroid of the GeoDataFrame\n",
    "m = folium.Map(location=[40.71380198, -73.91687195], zoom_start=10)\n",
    "\n",
    "# Add the choropleth layer\n",
    "folium.Choropleth(\n",
    "    geo_data=nyc_shp_subset.to_json(),\n",
    "    data=nyc_shp_subset,\n",
    "    columns=['nyc_tractIDs', 'log_pop_2001'],\n",
    "    key_on='feature.properties.nyc_tractIDs',\n",
    "    fill_color='Blues',\n",
    "    fill_opacity=0.7,\n",
    "    line_opacity=0.2,\n",
    "    legend_name='Log population per tract in 2001'\n",
    ").add_to(m)\n",
    "\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the map centered on the centroid of the GeoDataFrame\n",
    "m = folium.Map(location=[40.71380198, -73.91687195], zoom_start=10.5)\n",
    "\n",
    "# Add the choropleth layer\n",
    "folium.Choropleth(\n",
    "    geo_data=nyc_shp_subset.to_json(),\n",
    "    data=nyc_shp_subset.assign(events_2001 = lambda df: np.clip(df['events_2001'], 0, 15)),\n",
    "    columns=['nyc_tractIDs', 'events_2001'],\n",
    "    key_on='feature.properties.nyc_tractIDs',\n",
    "    fill_color='Blues',\n",
    "    line_opacity=0.1,\n",
    "    legend_name='Raw number of events per tract in 2001'\n",
    ").add_to(m)\n",
    "\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Baseline model: a simple Poisson GLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = len(nyc_shp_subset[\"events_2001\"])\n",
    "y = nyc_shp_subset[\"events_2001\"]\n",
    "E = nyc_shp_subset[\"pop_2001\"]\n",
    "\n",
    "# Set population > 0\n",
    "E[E < 10] = 10\n",
    "\n",
    "data = {\"N\": N, \"y\": y, \"E\": E}\n",
    "pois_model = CmdStanModel(stan_file=\"stan/pois.stan\")\n",
    "pois_model_stanfit = pois_model.sample(data=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vars = [\n",
    "    \"beta0\",\n",
    "    \"mu[1]\",\n",
    "    \"mu[2]\",\n",
    "    \"mu[3]\",\n",
    "    \"mu[500]\",\n",
    "    \"mu[1000]\",\n",
    "    \"mu[1500]\",\n",
    "    \"mu[1900]\",\n",
    "]\n",
    "\n",
    "pois_model_summary = pois_model_stanfit.summary()\n",
    "pois_model_summary.loc[vars]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_map(df, var):\n",
    "    m = folium.Map(location=[40.71380198, -73.91687195], zoom_start=10.5)\n",
    "    folium.Choropleth(\n",
    "        geo_data=df.to_json(),\n",
    "        data=df,\n",
    "        columns=[\"nyc_tractIDs\", var],\n",
    "        key_on=\"feature.properties.nyc_tractIDs\",\n",
    "        fill_color=\"Blues\",\n",
    "        line_opacity=0.1,\n",
    "    ).add_to(m)\n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu_index = pois_model_summary.index.str.contains(\"mu\")\n",
    "mu_mean = pois_model_summary.loc[mu_index, \"Mean\"].reset_index(drop=True)\n",
    "plot_map(nyc_shp_subset.assign(mu = mu_mean), \"mu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adding a vector of random effects (heterogeneous variation only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = len(nyc_shp_subset[\"events_2001\"])\n",
    "y = nyc_shp_subset[\"events_2001\"]\n",
    "E = nyc_shp_subset[\"pop_2001\"]\n",
    "\n",
    "# Set population > 0\n",
    "E[E < 10] = 10\n",
    "\n",
    "data = {\"N\": N, \"y\": y, \"E\": E}\n",
    "\n",
    "pois_re_model = CmdStanModel(stan_file=\"stan/pois_re.stan\")\n",
    "pois_re_model_stanfit = pois_re_model.sample(data=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vars = [\n",
    "    \"beta0\",\n",
    "    \"mu[1]\",\n",
    "    \"mu[2]\",\n",
    "    \"mu[3]\",\n",
    "    \"mu[500]\",\n",
    "    \"mu[1000]\",\n",
    "    \"mu[1500]\",\n",
    "    \"mu[1900]\",\n",
    "    \"theta[1]\", \n",
    "    \"theta[2]\", \"theta[3]\", \n",
    "    \"theta[500]\", \n",
    "    \"theta[1000]\", \n",
    "    \"theta[1500]\", \n",
    "    \"theta[1900]\"\n",
    "]\n",
    "\n",
    "pois_re_model_summary = pois_re_model_stanfit.summary()\n",
    "pois_re_model_summary.loc[vars]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu_index = pois_re_model_summary.index.str.contains(\"mu\")\n",
    "mu_mean = pois_re_model_summary.loc[mu_index, \"Mean\"].reset_index(drop=True)\n",
    "plot_map(nyc_shp_subset.assign(mu = mu_mean), \"mu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adding an ICAR component (spatial smoothing only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing the fitted BYM2 model for New York City and Brooklyn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu_index = bym2_nyc_model_summary.index.str.contains(\"mu\")\n",
    "mu_mean = bym2_nyc_model_summary.loc[mu_index, \"Mean\"].reset_index(drop=True)\n",
    "plot_map(nyc_shp_subset.assign(mu = mu_mean), \"mu\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stan-example",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
